{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbe50b3",
   "metadata": {},
   "source": [
    "Разобранными на лекции методами список того, что можно применять к метрикам-отношениям, не ограничивается.\n",
    "Относительно недавно (в 2018-м году) исследователи из Яндекса разработали классный метод анализа тестов над метриками-отношениями (прямо как у нас) вида x/y.\n",
    "\n",
    "Идея метода заключается в следующем:\n",
    "\n",
    "Вместо того, чтобы заталкивать в тест «поюзерные» CTR, можно сконструировать другую метрику и анализировать ее, но при этом гарантируется (в отличие от сглаженного CTR), что если тест на этой другой метрике «прокрасится» и увидит изменения, значит изменения есть и в метрике исходной (то есть в лайках на пользователя и в пользовательских CTR).\n",
    "\n",
    "При этом метод сам по себе очень прост. Что это за метрика такая?\n",
    "\n",
    "Считаем общий CTR в контрольной группе  𝐶𝑇𝑅𝑐𝑜𝑛𝑡𝑟𝑜𝑙=𝑠𝑢𝑚(𝑙𝑖𝑘𝑒𝑠)/𝑠𝑢𝑚(𝑣𝑖𝑒𝑤𝑠) \n",
    "Посчитаем в обеих группах поюзерную метрику  𝑙𝑖𝑛𝑒𝑎𝑟𝑖𝑧𝑒𝑑_𝑙𝑖𝑘𝑒𝑠=𝑙𝑖𝑘𝑒𝑠−𝐶𝑇𝑅𝑐𝑜𝑛𝑡𝑟𝑜𝑙∗𝑣𝑖𝑒𝑤𝑠 \n",
    "После чего сравним  t-тестом отличия в группах по метрике 𝑙𝑖𝑛𝑒𝑎𝑟𝑖𝑧𝑒𝑑_𝑙𝑖𝑘𝑒𝑠  \n",
    "Метод простой, гарантируется, что при приличном размере выборки (как у нас — подойдет) можно бесплатно увеличить чувствительность вашей метрики (или, по крайней мере, не сделать хуже). Как по мне, это ОЧЕНЬ круто.\n",
    "\n",
    "Проанализируйте тест между группами 0 и 3 по метрике линеаризованных лайков. Видно ли отличие? Стало ли 𝑝−𝑣𝑎𝑙𝑢𝑒 меньше?\n",
    "Проанализируйте тест между группами 1 и 2 по метрике линеаризованных лайков. Видно ли отличие? Стало ли 𝑝−𝑣𝑎𝑙𝑢𝑒 меньше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandahouse\n",
    "import scipy.stats as stats\n",
    "from read_db.CH import Getch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b240125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Getch('''\n",
    "SELECT exp_group,\n",
    "    user_id,\n",
    "    sum(action = 'like') as likes,\n",
    "    sum(action = 'view') as views\n",
    "FROM simulator_20220320.feed_actions\n",
    "WHERE toDate(time) between '2022-03-15' and '2022-03-21'\n",
    "GROUP BY exp_group, user_id''').df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadbe08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr0 = data[data.exp_group == 0].likes.sum()/data[data.exp_group == 0].views.sum()\n",
    "ctr1 = data[data.exp_group == 1].likes.sum()/data[data.exp_group == 0].views.sum()\n",
    "\n",
    "group0 = data[data.exp_group == 0].copy()\n",
    "group0['lin_ctr'] = data.apply(\n",
    "    lambda x: x['likes'] - ctr0*x['views'], axis=1)\n",
    "\n",
    "group1 = data[data.exp_group == 1].copy()\n",
    "group1['lin_ctr'] = data.apply(\n",
    "    lambda x: x['likes'] - ctr1*x['views'], axis=1)\n",
    "\n",
    "group2 = data[data.exp_group == 2].copy()\n",
    "group2['lin_ctr'] = data.apply(\n",
    "    lambda x: x['likes'] - ctr1*x['views'], axis=1)\n",
    "\n",
    "group3 = data[data.exp_group == 3].copy()\n",
    "group3['lin_ctr'] = data.apply(\n",
    "    lambda x: x['likes'] - ctr0*x['views'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376760d7",
   "metadata": {},
   "source": [
    "Группы 1 и 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6762e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.2841320431616983, pvalue=0.0223769815558559)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_smoothed_ctr(user_likes, user_views, global_ctr, alpha=5):\n",
    "    smoothed_ctr = (user_likes + alpha * global_ctr)/(user_views + alpha)\n",
    "    return smoothed_ctr\n",
    "\n",
    "global_ctr_1 = data[data.exp_group == 1].likes.sum()/data[data.exp_group == 1].views.sum()\n",
    "global_ctr_2 = data[data.exp_group == 2].likes.sum()/data[data.exp_group == 2].views.sum()\n",
    "\n",
    "group01 = data[data.exp_group == 1].copy()\n",
    "group01['smoothed_ctr'] = data.apply(\n",
    "    lambda x: get_smoothed_ctr(x['likes'], x['views'], global_ctr_1), axis=1)\n",
    "\n",
    "group02 = data[data.exp_group == 2].copy()\n",
    "group02['smoothed_ctr'] = data.apply(\n",
    "    lambda x: get_smoothed_ctr(x['likes'], x['views'], global_ctr_2), axis=1)\n",
    "\n",
    "stats.ttest_ind(group01.smoothed_ctr,\n",
    "                group02.smoothed_ctr,\n",
    "                equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab2d3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=6.1314288874704825, pvalue=8.930310308522553e-10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(group1.lin_ctr,\n",
    "                group2.lin_ctr,\n",
    "                equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a034fb6",
   "metadata": {},
   "source": [
    "Группы 0 и 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d75f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-16.34071506341663, pvalue=1.2314229288207137e-59)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_ctr_0 = data[data.exp_group == 0].likes.sum()/data[data.exp_group == 0].views.sum()\n",
    "global_ctr_3 = data[data.exp_group == 3].likes.sum()/data[data.exp_group == 3].views.sum()\n",
    "\n",
    "group00 = data[data.exp_group == 0].copy()\n",
    "group00['smoothed_ctr'] = data.apply(\n",
    "    lambda x: get_smoothed_ctr(x['likes'], x['views'], global_ctr_0), axis=1)\n",
    "\n",
    "group03 = data[data.exp_group == 3].copy()\n",
    "group03['smoothed_ctr'] = data.apply(\n",
    "    lambda x: get_smoothed_ctr(x['likes'], x['views'], global_ctr_3), axis=1)\n",
    "\n",
    "stats.ttest_ind(group00.smoothed_ctr,\n",
    "                group03.smoothed_ctr,\n",
    "                equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161017dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-15.214995460903827, pvalue=5.4914249479690016e-52)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(group0.lin_ctr,\n",
    "                group3.lin_ctr,\n",
    "                equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142baba7",
   "metadata": {},
   "source": [
    "Действительно, этот тест более чувствительный по сравнению с t-тестом по сглаженному CTR и снижает значение p-value на несколько порядков. В случае групп 0 и 3 p-value в любом случае был очень небольшим, но в случае групп 1 и 2 разница более заметна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa04f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
